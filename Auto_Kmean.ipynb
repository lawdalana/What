{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from optparse import OptionParser\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import sys\n",
    "import codecs\n",
    "import csv\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "from db_class import db\n",
    "import csv\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check Args ##\n",
    "# try:\n",
    "#     Args = sys.argv\n",
    "#     if(len(Args)!=3):\n",
    "#         raise EnvironmentError\n",
    "# except:\n",
    "#     print(\"Error !!\")\n",
    "#     print(\"Plese add 2 arguments {file:Story_header} {file:Story_header_seller}\\n\")\n",
    "#     exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Read file ####\n",
    "novel_header = list()\n",
    "data = list()\n",
    "label = list()\n",
    "Group_filter = [\"26\",\"27\",\"28\",\"29\",\"30\",\"19\"]\n",
    "index = 0\n",
    "with open(\"story_header_m04b.csv\",\"r+\",encoding=\"utf8\") as test:\n",
    "    reader = csv.reader(test)\n",
    "    for row in reader:\n",
    "        if(not row[2] in Group_filter):\n",
    "            novel_header.append(row[0:-4])\n",
    "            data.append(row[-4:])\n",
    "            label.append(0)\n",
    "del novel_header[0]\n",
    "del data[0]\n",
    "del label[0]\n",
    "index = len(novel_header)\n",
    "with open(\"story_header_sell.csv\",\"r+\",encoding=\"utf8\") as test:\n",
    "    reader = csv.reader(test)\n",
    "    for row in reader:\n",
    "        novel_header.append(row[0:-4])\n",
    "        data.append(row[-4:])\n",
    "        label.append(1)\n",
    "del novel_header[index]\n",
    "del data[index]\n",
    "del label[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################################\n",
    "################# Bubble sort ###########################\n",
    "#########################################################\n",
    "def sort():\n",
    "    global Result_value\n",
    "    global novel_header\n",
    "    global data\n",
    "    for x in range(len(Result_value)):\n",
    "        for y in range(len(Result_value)):\n",
    "            if(Result_value_all[x]>Result_value_all[y]):\n",
    "                Result_value_all[x], Result_value_all[y] = Result_value_all[y],Result_value_all[x]\n",
    "                novel_header[x], novel_header[y] = novel_header[y], novel_header[x]\n",
    "                data[x], data[y] = data[y], data[x]\n",
    "                label[x], label[y] = label[y], label[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################################\n",
    "################# function ##############################\n",
    "#########################################################\n",
    "def process(predict, cls):\n",
    "    global final\n",
    "    global final_all\n",
    "    global Result_value\n",
    "    global Result_value_all\n",
    "    \n",
    "    if not Result_value_all:\n",
    "        for k in range(cls):\n",
    "            count = 0\n",
    "            count_pls = 0\n",
    "            for loop in range(len(predict)):\n",
    "                if(predict[loop]==k):\n",
    "                    count = count + 1\n",
    "                    if(label[loop]==1):\n",
    "                        count_pls = count_pls + 1\n",
    "            final.append(count_pls)\n",
    "            final_all.append(count)\n",
    "            buffer = list()\n",
    "        for k in range(len(predict)):\n",
    "            val = (float(final[predict[k]])/float(final_all[predict[k]]))*(1-(float(final_all[predict[k]])/len(train_data)))\n",
    "            Result_value_all.append(val)\n",
    "            buffer.append(val)\n",
    "        Result_value.append(buffer)\n",
    "        final = list()\n",
    "        final_all = list()\n",
    "    else:\n",
    "        for k in range(cls):\n",
    "            count = 0\n",
    "            count_pls = 0\n",
    "            for loop in range(len(predict)):\n",
    "                if(predict[loop]==k):\n",
    "                    count = count + 1\n",
    "                    if(label[loop]==1):\n",
    "                        count_pls = count_pls + 1\n",
    "            final.append(count_pls)\n",
    "            final_all.append(count)\n",
    "            buffer = list()\n",
    "        for k in range(len(predict)):\n",
    "            val = (float(final[predict[k]])/float(final_all[predict[k]]))*(1-(float(final_all[predict[k]])/len(train_data)))\n",
    "            buffer.append(val)\n",
    "            if(val>Result_value_all[k]):\n",
    "                Result_value_all[k] = val\n",
    "                \n",
    "        Result_value.append(buffer)\n",
    "        final = list()\n",
    "        final_all = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "####################  Main  ####################\n",
    "################################################\n",
    "final = list()\n",
    "final_all = list()\n",
    "Result_value_all = list()\n",
    "Result_value = list()\n",
    "train_data = np.asarray(data)\n",
    "ite = 119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trans = np.asarray(data).T.tolist()\n",
    "Max_value = [float(max(Trans[0])), float(max(Trans[1])), float(max(Trans[2])), float(max(Trans[3]))]\n",
    "Min_value = [float(min(Trans[0])), float(min(Trans[1])), float(min(Trans[2])), float(min(Trans[3]))]\n",
    "dif_value = [Max_value[0]-Min_value[0], Max_value[1]-Min_value[1], Max_value[2]-Min_value[2], Max_value[3]-Min_value[3]]\n",
    "datax = deepcopy(data)\n",
    "for i in range(len(data)):\n",
    "    datax[i][0] = (float(datax[i][0]) - Min_value[0]) / dif_value[0]\n",
    "    datax[i][1] = (float(datax[i][1]) - Min_value[1]) / dif_value[1]\n",
    "    datax[i][2] = (float(datax[i][2]) - Min_value[2]) / dif_value[2]\n",
    "    datax[i][3] = (float(datax[i][3]) - Min_value[3]) / dif_value[3]\n",
    "del Trans\n",
    "del Min_value\n",
    "del Max_value\n",
    "del dif_value\n",
    "gc.collect()\n",
    "\n",
    "# convert data to array\n",
    "train_data = np.asarray(datax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2,ite):\n",
    "    kmeans = KMeans(n_clusters=i, max_iter=500 ,random_state=0).fit(train_data)\n",
    "    result = kmeans.labels_\n",
    "    result = result.tolist()\n",
    "    process(result, i)\n",
    "sort()\n",
    "    \n",
    "# with codecs.open(\"Result.csv\",\"w\",\"utf-8\") as test:\n",
    "#     for i in range(0,len(Result_value_all)):\n",
    "#         if(label[i]==0):\n",
    "#             head = \",\".join(novel_header[i])\n",
    "#             body = \",\".join(data[i])\n",
    "#             buf = str(head)+\",\"+str(body)+\",\"+str(Result_value_all[i])+\"\\n\"\n",
    "#             test.write(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open(\"Result_K.csv\",\"w\") as test:\n",
    "#     buf = \"\"\n",
    "#     for j in range(0,len(Result_value_all)):\n",
    "#         if(label[i]==1):\n",
    "#             for i in range(0,ite-4):\n",
    "#                 buf = buf + str(Result_value[i][j]) + \",\"\n",
    "#             buf = buf + str(Result_value[ite-3][j]) + \"\\n\"\n",
    "#             test.write(buf)\n",
    "#             buf = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  (1062, \"Duplicate entry '1616748' for key 'PRIMARY'\")\n",
      "Error:  (1062, \"Duplicate entry '1615063' for key 'PRIMARY'\")\n",
      "Error:  (1062, \"Duplicate entry '1627376' for key 'PRIMARY'\")\n",
      "Error:  (1062, \"Duplicate entry '1616723' for key 'PRIMARY'\")\n",
      "Error:  (1062, \"Duplicate entry '1619510' for key 'PRIMARY'\")\n",
      "Error:  (1062, \"Duplicate entry '1624401' for key 'PRIMARY'\")\n",
      "Error:  (1062, \"Duplicate entry '1630647' for key 'PRIMARY'\")\n",
      "Error:  (1062, \"Duplicate entry '1631297' for key 'PRIMARY'\")\n"
     ]
    }
   ],
   "source": [
    "database = db(\"localhost\", 3306,\"root\",\"1234\", \"test\")\n",
    "# for i in range(0,len(Result_value_all)):\n",
    "for i in range(0,len(Result_value_all)):\n",
    "    if(label[i]==0):\n",
    "        try:\n",
    "            datetime_object = datetime.strptime(novel_header[i][7], '%d/%m/%Y, %H:%M:%S')\n",
    "        except:\n",
    "            datetime_object = novel_header[i][7]\n",
    "        buffer = \"INSERT INTO result SET \\\n",
    "                id=\" + str(novel_header[i][0]) + \",\"+\\\n",
    "                \"main_group=\" + str(novel_header[i][1]) + \",\"+\\\n",
    "                \"groupa=\" + str(novel_header[i][2]) + \",\"+\\\n",
    "                \"username=\\\"\" + str(novel_header[i][3]) + \"\\\",\"+\\\n",
    "                \"title= %s ,\"+\\\n",
    "                \"type=\" + str(novel_header[i][5]) + \",\"+\\\n",
    "                \"is_end=\" + str(novel_header[i][6]) + \",\"+\\\n",
    "                \"updated=\\\"\" + str(datetime_object) +\"\\\",\"+\\\n",
    "                \"is_ban=\" + str(novel_header[i][8]) + \",\"+\\\n",
    "                \"is_lock=\" + str(novel_header[i][9]) + \",\"+\\\n",
    "                \"published=\\\"\" + str(novel_header[i][10]) + \"\\\",\"+\\\n",
    "                \"isbad=\" + str(novel_header[i][11]) + \",\"+\\\n",
    "                \"pack_draft=\" + str(novel_header[i][12]) + \",\"+\\\n",
    "                \"pack_selling=\" + str(novel_header[i][13]) + \",\"+\\\n",
    "                \"status=\" + str(novel_header[i][14]) + \",\"+\\\n",
    "                \"fav=\" + str(data[i][0]) + \",\"+\\\n",
    "                \"chapter=\" + str(data[i][1]) + \",\"+\\\n",
    "                \"visitor_all=\" + str(data[i][2]) + \",\"+\\\n",
    "                \"visitor=\" + str(data[i][3]) + \",\"+\\\n",
    "                \"result_value=\" + str(Result_value_all[i])+ \",\"+\\\n",
    "                \"label=\" + str(0)\n",
    "        database.CURD_SP(buffer, novel_header[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del database"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
